### **Examen : 20 Questions pour Comprendre l‚ÄôImpl√©mentation d‚Äôun R√©seau de Neurones avec PyTorch**

üìå **Instructions :**  
- **Analysez le code fourni** avant chaque section.  
- **R√©pondez aux questions** bas√©es sur l‚Äôimpl√©mentation et le fonctionnement du mod√®le PyTorch.  
- **Objectif :** Acqu√©rir une compr√©hension **pratique et approfondie** de la construction d‚Äôun r√©seau de neurones en PyTorch.  



## **üìù Partie 1 : Importation des Biblioth√®ques**

### **Code :**
```python
import torch
from torch import nn, optim, utils
import numpy as np
import matplotlib.pyplot as plt
```

### **Contexte :**  
Ce segment de code importe **PyTorch**, **NumPy** et **Matplotlib**.  
- **PyTorch** est utilis√© pour construire et entra√Æner le r√©seau de neurones.  
- **NumPy** sert √† manipuler les donn√©es num√©riques.  
- **Matplotlib** permet de visualiser les r√©sultats.  

### **Question 1**  
Pourquoi utilisons-nous PyTorch (`torch`) dans ce projet ?  

A. Pour manipuler facilement des **matrices et tenseurs** et entra√Æner des mod√®les de deep learning.  
B. Pour am√©liorer la vitesse d‚Äôentra√Ænement d‚Äôun mod√®le scikit-learn.  
C. Pour g√©n√©rer automatiquement des jeux de donn√©es simul√©es.  
D. Pour normaliser les variables d‚Äôentr√©e du mod√®le.  



## **üìù Partie 2 : G√©n√©ration des Donn√©es Simul√©es**

### **Code :**
```python
# G√©n√©ration de donn√©es simul√©es
np.random.seed(42)
torch.manual_seed(42)

# Donn√©es : quantit√© de mati√®re premi√®re, temps de production, co√ªt main d'≈ìuvre
X_data = np.random.rand(1000, 3) * 10  # 1000 √©chantillons avec 3 variables
y_data = 3 * X_data[:, 0] + 2 * X_data[:, 1] + 4 * X_data[:, 2] + np.random.randn(1000) * 2
```

### **Contexte :**  
- On **g√©n√®re artificiellement des donn√©es** pour entra√Æner le mod√®le.  
- Chaque √©chantillon a **3 variables d‚Äôentr√©e** (quantit√© de mati√®re, temps de production, co√ªt de main-d‚Äô≈ìuvre).  
- La **relation entre les variables et la sortie** est lin√©aire, avec un bruit ajout√© pour simuler des variations r√©elles.  

### **Question 2**  
Pourquoi utilisons-nous `np.random.seed(42)` et `torch.manual_seed(42)` ?  

A. Pour garantir que **les m√™mes donn√©es sont g√©n√©r√©es** √† chaque ex√©cution du script.  
B. Pour r√©duire la complexit√© du mod√®le.  
C. Pour permettre au mod√®le de mieux g√©n√©raliser sur des donn√©es inconnues.  
D. Pour am√©liorer la pr√©cision du mod√®le.  



## **üìù Partie 3 : S√©paration des Donn√©es**

### **Code :**
```python
# S√©paration des donn√©es (80% train, 20% test)
train_size = int(0.8 * len(X_data))
X_train, X_test = X_data[:train_size], X_data[train_size:]
y_train, y_test = y_data[:train_size], y_data[train_size:]
```

### **Contexte :**  
- On **divise les donn√©es** en un ensemble d‚Äôentra√Ænement (**80%**) et un ensemble de test (**20%**).  
- L‚Äôobjectif est de **v√©rifier si le mod√®le est capable de g√©n√©raliser** sur des donn√©es qu‚Äôil n‚Äôa jamais vues.  

### **Question 3**  
Pourquoi devons-nous s√©parer les donn√©es en **train (80%) et test (20%)** ?  

A. Pour √©valuer si le mod√®le **g√©n√©ralise bien** sur de nouvelles donn√©es.  
B. Pour augmenter la vitesse d‚Äôentra√Ænement du mod√®le.  
C. Pour √©viter d‚Äôavoir trop de donn√©es dans l‚Äôensemble d‚Äôentra√Ænement.  
D. Pour ajuster les hyperparam√®tres du mod√®le en temps r√©el.  



## **üìù Partie 4 : Cr√©ation du Dataset et DataLoader**

### **Code :**
```python
class ProductionDataset(utils.data.Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Ajouter une dimension

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# Cr√©ation des datasets
train_dataset = ProductionDataset(X_train, y_train)
test_dataset = ProductionDataset(X_test, y_test)

# Chargement avec DataLoader
train_loader = utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = utils.data.DataLoader(test_dataset, batch_size=32)
```

### **Contexte :**  
- **`ProductionDataset`** structure les donn√©es sous forme de `torch.Tensor`.  
- `DataLoader` charge les donn√©es **par batchs** pour faciliter l‚Äôentra√Ænement.  
- **`shuffle=True`** m√©lange les donn√©es √† chaque epoch pour √©viter un biais d‚Äôapprentissage.  

### **Question 4**  
Quel est **l‚Äôavantage principal** d‚Äôutiliser `DataLoader` dans PyTorch ?  

A. Il **charge les donn√©es en m√©moire par lots** et optimise la gestion des calculs.  
B. Il entra√Æne automatiquement le mod√®le √† chaque batch.  
C. Il transforme les donn√©es en valeurs normalis√©es.  
D. Il ajuste les poids du mod√®le en fonction de la perte.  



## **üìù Partie 5 : D√©finition du Mod√®le**

### **Code :**
```python
class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(3, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )

    def forward(self, x):
        return self.model(x)

# Initialisation du mod√®le
model = NeuralNetwork()
```

### **Contexte :**  
- Le r√©seau a **3 couches cach√©es** avec `ReLU` comme activation.  
- Il prend **3 entr√©es** et g√©n√®re **une sortie** (co√ªt estim√©).  

### **Question 5**  
Pourquoi utilisons-nous la fonction d‚Äôactivation `ReLU()` dans ce mod√®le ?  

A. Pour rendre le mod√®le **non lin√©aire** et capturer des relations complexes.  
B. Pour am√©liorer la vitesse de convergence du mod√®le.  
C. Pour transformer toutes les valeurs n√©gatives en positives.  
D. Pour r√©duire le temps d‚Äôentra√Ænement.  



## **üìù Partie 6 : Entra√Ænement du Mod√®le**

### **Code :**
```python
optimizer = optim.Adam(model.parameters(), lr=0.01)
loss_fn = nn.MSELoss()
```

### **Contexte :**  
- **Optimiseur `Adam`** met √† jour les poids du mod√®le √† chaque it√©ration.  
- **Fonction de perte `MSELoss()`** mesure l‚Äô√©cart entre la pr√©diction et la r√©alit√©.  

### **Question 6**  
Pourquoi utilisons-nous `MSELoss()` comme fonction de co√ªt ?  

A. Parce qu‚Äôelle est adapt√©e aux **probl√®mes de r√©gression**.  
B. Parce qu‚Äôelle mesure l‚Äôerreur en classification.  
C. Parce qu‚Äôelle corrige automatiquement les erreurs du mod√®le.  
D. Parce qu‚Äôelle est plus rapide que `CrossEntropyLoss()`.  



## **üìù Partie 7 : Fonction d'Entra√Ænement et d'√âvaluation**

### **Code :**
```python
def train_model(dataloader, model, loss_fn, optimizer):
    model.train()
    total_loss = 0
    for X_batch, y_batch in dataloader:
        optimizer.zero_grad()
        predictions = model(X_batch)
        loss = loss_fn(predictions, y_batch)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(dataloader)
```

### **Contexte :**  
- `optimizer.zero_grad()` r√©initialise les gradients.  
- `loss.backward()` **calcule le gradient**.  
- `optimizer.step()` **met √† jour les poids**.  

### **Question 7**  
Que fait `optimizer.step()` dans cette fonction d'entra√Ænement ?  

A. **Met √† jour les poids** du mod√®le.  
B. Calcule la perte actuelle.  
C. R√©initialise les gradients.  
D. Modifie la structure du r√©seau.  













## **üìù Partie 8 : √âvaluation du Mod√®le**

### **Code :**
```python
def evaluate_model(dataloader, model, loss_fn):
    model.eval()
    total_loss = 0
    with torch.no_grad():
        for X_batch, y_batch in dataloader:
            predictions = model(X_batch)
            loss = loss_fn(predictions, y_batch)
            total_loss += loss.item()
    return total_loss / len(dataloader)
```

### **Contexte :**  
- `model.eval()` **d√©sactive certaines couches** comme Dropout.  
- `torch.no_grad()` **r√©duit la consommation m√©moire** en **d√©sactivant le calcul des gradients**.  
- On calcule la **perte moyenne sur l‚Äôensemble de test**.

### **Question 8**  
Pourquoi utilisons-nous `with torch.no_grad()` lors de l‚Äô√©valuation ?  

A. Pour **d√©sactiver le calcul des gradients** et √©conomiser de la m√©moire.  
B. Pour emp√™cher les donn√©es de test d‚Äô√™tre modifi√©es.  
C. Pour rendre les pr√©dictions plus rapides.  
D. Pour √©viter la mise √† jour des poids du mod√®le.  


## **üìù Partie 9 : Entra√Ænement du Mod√®le**

### **Code :**
```python
num_epochs = 50
train_losses = []
test_losses = []

for epoch in range(num_epochs):
    train_loss = train_model(train_loader, model, loss_fn, optimizer)
    test_loss = evaluate_model(test_loader, model, loss_fn)
    train_losses.append(train_loss)
    test_losses.append(test_loss)
    print(f"Epoch {epoch + 1}/{num_epochs} - Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}")
```

### **Contexte :**  
- **On entra√Æne le mod√®le pendant 50 epochs**.  
- On stocke **les pertes d‚Äôentra√Ænement et de test** pour analyser la convergence.  

### **Question 9**  
Comment pouvons-nous savoir si le mod√®le **surapprend (overfitting) ?**  

A. Si la **perte d'entra√Ænement est basse** mais que la **perte de test reste √©lev√©e**.  
B. Si la perte de test est plus basse que la perte d‚Äôentra√Ænement.  
C. Si le mod√®le atteint une pr√©cision de 100% apr√®s 10 epochs.  
D. Si la fonction d‚Äôactivation utilis√©e est `ReLU()`.  



## **üìù Partie 10 : Visualisation des Performances**

### **Code :**
```python
plt.figure(figsize=(10, 5))
plt.plot(range(num_epochs), train_losses, label="Train Loss")
plt.plot(range(num_epochs), test_losses, label="Test Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Loss during Training and Testing")
plt.legend()
plt.show()
```

### **Contexte :**  
- On **visualise la courbe d‚Äôapprentissage** du mod√®le.  
- Une **courbe de perte qui diminue progressivement** signifie que l‚Äôentra√Ænement se passe bien.  

### **Question 10**  
Que signifie une **courbe de perte d‚Äôentra√Ænement qui diminue mais une courbe de test qui stagne ou augmente** ?  

A. Le mod√®le est **en overfitting**.  
B. Le mod√®le est **sous-entra√Æn√© (underfitting)**.  
C. Le mod√®le a une bonne g√©n√©ralisation.  
D. Il faut augmenter le taux d‚Äôapprentissage (`learning rate`).  



## **üìù Partie 11 : √âvaluation Finale du Mod√®le**

### **Code :**
```python
model.eval()
X_sample = torch.tensor(X_test[:5], dtype=torch.float32)
y_sample = y_test[:5]

predictions = model(X_sample).detach().numpy()
for i, (real, pred) in enumerate(zip(y_sample, predictions)):
    print(f"Sample {i + 1}: Real Value = {real:.2f}, Predicted Value = {pred[0]:.2f}")
```

### **Contexte :**  
- On **compare les pr√©dictions du mod√®le** avec les valeurs r√©elles sur 5 exemples.  
- `detach().numpy()` **convertit les tenseurs PyTorch en NumPy** pour affichage.  

### **Question 11**  
Pourquoi utilisons-nous `.detach().numpy()` avant d‚Äôafficher les pr√©dictions ?  

A. Pour **convertir les tenseurs PyTorch en tableaux NumPy** et faciliter leur affichage.  
B. Pour acc√©l√©rer les calculs.  
C. Pour sauvegarder les r√©sultats en m√©moire.  
D. Parce que NumPy est plus pr√©cis que PyTorch.  



## **üìù Partie 12 : Optimisation du Mod√®le**

### **Code :**
```python
optimizer = optim.Adam(model.parameters(), lr=0.001)
```

### **Contexte :**  
- `lr=0.001` d√©finit le **taux d‚Äôapprentissage** (learning rate).  
- Si `lr` est trop **√©lev√©**, le mod√®le peut **diverger**.  
- Si `lr` est trop **faible**, l‚Äôapprentissage sera **trop lent**.  

### **Question 12**  
Que se passe-t-il si le taux d‚Äôapprentissage (`lr`) est **trop √©lev√©** ?  

A. Le mod√®le risque **de ne jamais converger** et d‚Äôosciller entre diff√©rentes valeurs.  
B. Le mod√®le apprendra plus vite et sera plus pr√©cis.  
C. Le mod√®le prendra plus de temps pour apprendre.  
D. Le mod√®le ne pourra jamais faire d‚Äôerreur.  



## **üìù Partie 13 : Exp√©rimentation avec un R√©seau Profond (5 Couches)**

### **Code :**
```python
class DeepNeuralNetwork(nn.Module):
    def __init__(self):
        super(DeepNeuralNetwork, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(3, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1)
        )

    def forward(self, x):
        return self.model(x)
```

### **Contexte :**  
- **Ce r√©seau contient 5 couches cach√©es**, au lieu de 2 pr√©c√©demment.  
- Il peut **apprendre des relations plus complexes**, mais peut aussi **surajuster (overfitting)**.  

### **Question 13**  
Pourquoi ajouter **plus de couches** dans un r√©seau de neurones ?  

A. Pour capturer des **relations plus complexes** dans les donn√©es.  
B. Pour rendre l‚Äôentra√Ænement plus rapide.  
C. Pour √©viter compl√®tement le surajustement.  
D. Pour utiliser plus de m√©moire GPU.  



## **üìù Partie 14 : Strat√©gies de Pr√©vention du Surapprentissage**

### **Question 14**  
Quelle **technique** peut aider √† **√©viter le surajustement** ?  

A. **Ajouter du Dropout** entre les couches cach√©es.  
B. Augmenter la taille du batch (`batch_size`).  
C. D√©sactiver `ReLU()`.  
D. Supprimer l‚Äôensemble de test.  



## **üìù Partie 15 : Comparaison avec une R√©gression Lin√©aire**

### **Question 15**  
Quelle est la **diff√©rence** entre une **r√©gression lin√©aire classique** et un **r√©seau de neurones** ?  

A. Un **r√©seau de neurones** peut **apprendre des relations non lin√©aires**.  
B. Une **r√©gression lin√©aire** est plus rapide mais moins flexible.  
C. Un **r√©seau de neurones** fonctionne mieux avec **des donn√©es complexes**.  
D. **Toutes les r√©ponses sont correctes**.  






## **üìù Partie 16 : Choix du Batch Size et Son Impact**  

### **Code :**  
```python
train_loader = utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = utils.data.DataLoader(test_dataset, batch_size=64)
```

### **Contexte :**  
- **`batch_size=64`** signifie que les donn√©es seront trait√©es **par lots de 64 √©chantillons** au lieu de tout charger d‚Äôun coup.  
- Un **batch size plus grand** acc√©l√®re l‚Äôapprentissage, mais **demande plus de m√©moire GPU**.  
- Un **batch size trop petit** peut produire des **gradients instables**.  

### **Question 16**  
Quel est **l'impact du choix de la taille des batchs (`batch_size`)** pendant l‚Äôentra√Ænement du mod√®le ?  

A. Un **batch size plus grand** permet d‚Äôentra√Æner le mod√®le **plus rapidement**, mais n√©cessite **plus de m√©moire**.  
B. Un **batch size plus petit** permet d‚Äôavoir **des gradients plus pr√©cis**, mais ralentit l‚Äôentra√Ænement.  
C. Un **batch size trop grand** peut faire **diverger** l‚Äôoptimisation du mod√®le.  
D. **Toutes les r√©ponses sont correctes.**  

---

## **üìù Partie 17 : Fonction de Perte et Alternatives**  

### **Code :**  
```python
loss_fn = nn.MSELoss()
```

### **Contexte :**  
- **MSELoss (Mean Squared Error)** est couramment utilis√©e pour **les probl√®mes de r√©gression**.  
- Elle **p√©nalise davantage** les erreurs importantes (grandes diff√©rences entre la pr√©diction et la valeur r√©elle).  
- D‚Äôautres fonctions de perte comme `L1Loss` ou `HuberLoss` peuvent √™tre utilis√©es selon le contexte.  

### **Question 17**  
Pourquoi utilisons-nous **MSELoss (Mean Squared Error)** comme fonction de perte dans ce mod√®le de r√©gression ?  

A. Parce que c‚Äôest une **fonction adapt√©e aux probl√®mes de r√©gression** et qu‚Äôelle punit les grandes erreurs.  
B. Parce qu‚Äôelle **fonctionne mieux avec des classes discr√®tes**.  
C. Parce qu‚Äôelle force le mod√®le √† **ne pr√©dire que des valeurs positives**.  
D. Parce qu‚Äôelle est plus rapide que `CrossEntropyLoss()`.  

---

## **üìù Partie 18 : Comparaison des Optimiseurs**  

### **Code :**  
```python
optimizer = optim.Adam(model.parameters(), lr=0.01)
```

### **Contexte :**  
- **Adam** est un optimiseur qui ajuste **automatiquement** le taux d‚Äôapprentissage (`lr`) pour chaque param√®tre du mod√®le.  
- Il est souvent pr√©f√©r√© √† **SGD (Stochastic Gradient Descent)**, car **il converge plus rapidement** et √©vite les minimas locaux.  
- SGD peut √™tre utilis√© avec **momentum** pour am√©liorer sa stabilit√©.  

### **Question 18**  
Pourquoi `Adam` est-il souvent pr√©f√©r√© √† `SGD` (Stochastic Gradient Descent) ?  

A. Parce qu‚Äôil ajuste **automatiquement le taux d‚Äôapprentissage** pour chaque param√®tre du mod√®le.  
B. Parce qu‚Äôil est **moins sensible aux minimas locaux** que `SGD`.  
C. Parce qu‚Äôil converge **plus rapidement** dans la plupart des cas.  
D. **Toutes les r√©ponses sont correctes.**  


## **üìù Partie 19 : Gestion des Probl√®mes de Convergence**  

### **Code :**  
```python
optimizer = optim.Adam(model.parameters(), lr=0.001)
```

### **Contexte :**  
- **Un mod√®le qui ne converge pas** signifie que la perte ne diminue pas correctement.  
- **Causes possibles** :
  1. **Taux d‚Äôapprentissage trop √©lev√©** ‚Üí Oscillations sans convergence.  
  2. **Donn√©es insuffisantes** ‚Üí Pas assez d'exemples pour g√©n√©raliser.  
  3. **Mod√®le trop simple** ‚Üí Il ne peut pas capturer les relations complexes.  

### **Question 19**  
Si un mod√®le **ne converge pas** (c'est-√†-dire que la perte ne diminue pas), quelle peut √™tre la cause principale ?  

A. **Un taux d‚Äôapprentissage (`lr`) trop √©lev√©** qui emp√™che la convergence.  
B. **Un manque de donn√©es** pour apprendre correctement.  
C. **Un mod√®le trop simple** qui ne capture pas bien la relation entre les variables.  
D. **Toutes les r√©ponses sont correctes.**  

---

## **üìù Partie 20 : Sauvegarde et Chargement du Mod√®le**  

### **Code :**  
```python
torch.save(model.state_dict(), "modele.pth")
```

### **Contexte :**  
- **Apr√®s l‚Äôentra√Ænement**, on veut **sauvegarder le mod√®le** pour √©viter de devoir le r√©entra√Æner.  
- **`state_dict()`** contient **tous les poids du mod√®le**, qu‚Äôon peut recharger plus tard avec `torch.load()`.  
- Cela permet de **restituer le mod√®le sans devoir recommencer l‚Äôentra√Ænement**.  

### **Question 20**  
Comment peut-on **sauvegarder un mod√®le entra√Æn√©** en PyTorch ?  

A. En utilisant `torch.save(model.state_dict(), "modele.pth")`.  
B. En exportant les poids du mod√®le avec NumPy.  
C. En copiant le code source du mod√®le.  
D. Il n‚Äôest pas possible de sauvegarder un mod√®le en PyTorch.  
